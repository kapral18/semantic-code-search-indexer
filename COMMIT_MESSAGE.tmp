refactor: Improve indexer memory efficiency and visibility

- Refactors both full and incremental indexers to use a serial, "double-batching" process. Files are processed one by one, and the resulting chunks are indexed in batches. This significantly reduces peak memory consumption.
- Re-introduces a dedicated progress bar for chunk indexing, restoring visibility into the indexing stage that was lost in the previous refactor.
- Reverts Elasticsearch environment variables to `ELASTICSEARCH_ENDPOINT` and `ELASTICSEARCH_USER` to maintain configuration consistency.

Prompts:

- "I think we need to re-work the indexer so that it parses 100 (BATCH) files then indexes 100 (BATCH) files, serially. The problem I'm seeing is that on my indexing node, it only has 4G of ram and the parser rips through all the files quickly and eventually runs out of memory. We basically need the indexer to be memory bound and as efficent memory-wise as possible."
- "Processing does 100, but it doesnt look like indexing does anything."
- "So if the first 100 files generates 700 chunks, will the indexer try and index all 700 chunks at a time?"
- "When did you change the config variables for ELASTICSEARCH_USER to ELASTICSEARCH_USERNAME and ELASTICSEARCH_ENDPOINT to ELASTICSEARCH_URL?"
- "Can you please change it back, now everything is out of sync"
- "With the last update to the indexer, I lost visibility on the indexing."

ðŸ¤– This commit was assisted by Gemini CLI
