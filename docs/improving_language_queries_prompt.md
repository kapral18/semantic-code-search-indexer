# Reusable Prompt: Improving Indexer Language Queries by Comparing Files and Chunks

This document outlines a reusable process for analyzing and improving the accuracy of the semantic code indexer's language parsing. By comparing a source file's content with the "chunks" generated by the indexer, we can identify gaps in the tree-sitter queries and refine them to create a more accurate and semantic index.

## Methodology

The core methodology involves a side-by-side comparison between the ground truth (the source file) and the indexer's interpretation (the chunks).

1.  **Baseline Analysis**: First, we read the original source code file to get a clear understanding of its structure, syntax, and content. This is our "ground truth."

2.  **Indexer Output Review**: Next, we use the MCP tools to retrieve the indexed "chunks" for that same file. This shows us exactly how our current parsing logic interprets the code and breaks it down.

3.  **Comparative Analysis (The Core Task)**: With both views available, we perform a detailed comparison. The goal is to spot discrepancies, such as:
    *   **Missing Code**: Important functions, classes, variables, or expressions that are present in the source file but do not appear in the chunks.
    *   **Incorrectly Grouped Code**: Chunks that are too large and merge unrelated concepts, or chunks that are too small and fragment a single logical block.
    *   **Poorly Classified Code**: Chunks that have an incorrect or overly generic `kind` (e.g., a function call being labeled as a generic `identifier` instead of a `call_expression`).

4.  **Identify the Query Gap**: Based on the discrepancies found, we form a hypothesis about what is wrong with the underlying tree-sitter query in the corresponding language file (located in `src/languages/`). For example, "The current query for `function_declaration` doesn't account for anonymous arrow functions."

5.  **Refine and Test**: Finally, we modify the appropriate language query file to fix the gap. After the change, the file can be re-indexed, and we can repeat this process to verify that the new chunks are more accurate.

## How to Use the MCP Tools

Here is the practical workflow using the available MCP tools:

**Step 1: Read the Source File**
Use the `read_file` tool to get the content of the source file you want to analyze.

```
[tool_code]
print(read_file(absolute_path="/path/to/your/file.ext"))
[/tool_code]
```

**Step 2: Read the Indexed Chunks**
Use the `read_file_from_chunks` tool to see how the indexer has parsed that same file.

```
[tool_code]
print(read_file_from_chunks(filePaths=["/path/to/your/file.ext"]))
[/tool_code]
```

**Step 3: Analyze and Propose Changes**
After running the commands above, compare their outputs. Once you have identified a discrepancy and have a hypothesis, you can read the relevant language file (e.g., `src/languages/typescript.ts`) and propose a change to its `queries` string.

---

## User Prompt Template

**(You can copy and paste the section below to start a new analysis)**

**Goal**: Improve the indexing for `[LANGUAGE_NAME]`.

**File to Analyze**: `[FULL_PATH_TO_FILE]`

**Problem Description**:
`[Describe the issue you are seeing. For example: "I've noticed that in Python files, comments inside functions are not being indexed correctly. They seem to be ignored by the chunking process."]`

**Let's begin the analysis.**
